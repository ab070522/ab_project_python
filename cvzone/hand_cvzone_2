import cv2
from cvzone.HandTrackingModule import HandDetector
# https://google.github.io/mediapipe/solutions/hands.html 손바닥 , 가락 순서 사이즈

#mediapipe hand
# 카메라를 VideoCapture 객체로 가져온다.
# https://github.com/cvzone
cap = cv2.VideoCapture(0)
# Minimum Detection Confidence Threshold
detector = HandDetector(detectionCon=0.8)

while True:
    # 계속해서 이미지를 불러와서 영상을 보여준다.
    success, img = cap.read()
    # Find the hand and its landmarks
    # 이미지 좌우 반전
    img = cv2.flip(img, 1)
    hands, img = detector.findHands(img)  # with draw
    # hands = detector.findHands(img, draw=False)  # without draw
    if hands:
        hand1 = hands[0]
        lmList1 = hand1["lmList"]  # List of 21 Landmark points
        bbox1 = hand1["bbox"]  # Bounding box info x,y,w,h
        centerPoint1 = hand1['center']  # center of the hand cx,cy
        handType1 = hand1["type"]  # Handtype Left or Right
        fingers1 = detector.fingersUp(hand1)
        detector.findDistance((lmList1[6][0], lmList1[6][1]), (lmList1[8][0], lmList1[8][1]), img)
        detector.findDistance((lmList1[10][0],lmList1[10][1]), (lmList1[12][0], lmList1[12][1]), img)
        detector.findDistance((lmList1[14][0], lmList1[14][1]), (lmList1[16][0], lmList1[16][1]), img)
        detector.findDistance((lmList1[18][0], lmList1[18][1]), (lmList1[20][0], lmList1[20][1]), img)
        detector.findDistance((lmList1[2][0], lmList1[2][1]), (lmList1[4][0], lmList1[4][1]), img)
        if lmList1[8][1] > lmList1[6][1] and lmList1[12][1] < lmList1[6][1] and lmList1[16][1] > lmList1[14][1] and lmList1[20][1] > lmList1[18][1] and lmList1[2][0] < lmList1[4][0]:
            print("bend")


    cv2.imshow("Image", img)
    cv2.waitKey(1)
cap.release()
cv2.destroyAllWindows()
